{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN2eG0AA2qTJ5BcpvJrtJ8H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 제목: Tabular Playground Series - Jan 2021\n","\n","수상작 리뷰\n","\n","## **대회목표**\n","\n",": 여러 개의 피처(특성) 열이 주어진 데이터를 기반으로, 연속적인 타깃 값을 예측\n","\n","## **데이터:**\n","\n","train.csv : id, 14개의 연속형 변수, target으로 이루어짐\n","test.csv : id, 14개의 연속형변수로 이루어짐\n","\n","### **1. 데이터 로드**\n","\n","데이터를 불러온 이후 각 fold별로 데이터를 나우서 학습을 준비하였는데, 이때 x_train에 절대값을 취함\n","\n","### **2. 모델 학습**\n","4가지 주요 모델을 개별 학습한 이휴 stacking을 이용함\n","\n","### **첫번째 모델 **: 단순 LightGBM (lgbm)\n","-기본 특징만 사용한 회귀 모델\n","\n","### **두번째 모델**: 2-stage LightGBM 이요\n","1) target을 특정 임계값인 8로 하여 이진 분류함\n","2) 두개의 subset으로 각각 회귀 모델을 학습\n","-> 최종 예측을 할때에는\n","final_prediction = probability_of_being_0 (predictions_from_training_0) + probability_of_being_1 (predictions_from_training_1) 다음과 같이 진행함.\n","\n","### **-3번째 모델**\n",": DAE를 이용한 데이터 증강 활용함\n","\n","### **-4번째 모델:**\n","연속형 변수들을 가공하여 범주형 특성으로 변환한 뒤, 이들을 임베딩 레이어에 넣어 신경망(MLP) 모델로 학습함.\n","\n","각 모델이 생성한 OOF predictions을 기반으로, 이들을 입력으로 하는 선형 회귀 모델을 학습시켜 최종 예측을 만드는 스태킹 기법을 사용\n","\n","### **배울점**\n","-LGBM , 2-satge 모델링, DAE를 이용하는 등 서로 다른 방식의 모델을 조합하여 스태킹 효과를 극대화하여서, 다음에 stacking 모델을 적용할 경우에는 배웠던 모델 뿐만 아니라 여러 다양한 모델을 적용하기 위해서 노력해야겠다."],"metadata":{"id":"jNKL3LppiX4p"}}]}
